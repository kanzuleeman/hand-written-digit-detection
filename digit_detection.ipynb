{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3965412d-7555-4c50-b86d-b1da91a8d0ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: [0.69693744]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Neuron_net:\n",
    "    def __init__(self, input_size):\n",
    "        self.weights = np.random.rand(input_size)\n",
    "        self.bias = np.random.rand(1)\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def feed_forward(self, inputs):\n",
    "        total = np.dot(inputs, self.weights) + self.bias\n",
    "        return self.sigmoid(total)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    neuron = Neuron_net(input_size=3)\n",
    "    inputs = np.array([0.1, 1.4, 4])\n",
    "    output = neuron.feed_forward(inputs)\n",
    "    print(\"Output:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fbd6254-718c-433f-a03b-d67761d574aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Training Loss: 1.4520, Validation Loss: 1.4370\n",
      "Epoch 20, Training Loss: 0.7783, Validation Loss: 0.7578\n",
      "Epoch 30, Training Loss: 0.6441, Validation Loss: 0.6193\n",
      "Epoch 40, Training Loss: 0.6087, Validation Loss: 0.5883\n",
      "Epoch 50, Training Loss: 0.5621, Validation Loss: 0.5394\n",
      " Accuracy: 82.81%\n",
      "Precision for class 0: 0.8577\n",
      "Precision for class 1: 0.9214\n",
      "Precision for class 2: 0.9591\n",
      "Precision for class 3: 0.9489\n",
      "Precision for class 4: 0.9315\n",
      "Precision for class 5: 0.9147\n",
      "Precision for class 6: 0.8049\n",
      "Precision for class 7: 0.9674\n",
      "Precision for class 8: 0.5997\n",
      "Precision for class 9: 0.6681\n"
     ]
    }
   ],
   "source": [
    "import numpy as np         \n",
    "import pandas as pd\n",
    "\n",
    "def precision_score(y_true, y_pred):\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    \n",
    "    if tp + fp == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return tp / (tp + fp)\n",
    "\n",
    "def load_data():\n",
    "    train_data=pd.read_csv('mnist_train.csv')\n",
    "    test_data=pd.read_csv('mnist_test.csv')\n",
    "\n",
    "    X_train=train_data.iloc[:,1:].values.astype(np.float32)/255.0\n",
    "    X_test=test_data.iloc[:,1:].values.astype(np.float32)/255.0\n",
    "\n",
    "    y_train=train_data.iloc[:,0].values\n",
    "    y_test=test_data.iloc[:,0].values\n",
    "\n",
    "    y_train_onehot=np.zeros((y_train.size,y_train.max()+1))\n",
    "    y_train_onehot[np.arange(y_train.size), y_train] = 1\n",
    "\n",
    "    y_test_onehot=np.zeros((y_test.size,y_test.max()+1))\n",
    "    y_test_onehot[np.arange(y_test.size), y_test] = 1\n",
    "\n",
    "    return X_train,y_train_onehot,X_test,y_test_onehot\n",
    "\n",
    "\n",
    " \n",
    "class Neural_network:\n",
    "    def __init__(self,input_size,hidden_size,output_size,learning_rate,regularization):\n",
    "        self.input_size=input_size\n",
    "        self.hidden_size=hidden_size\n",
    "        self.output_size=output_size\n",
    "        self.learning_rate=learning_rate\n",
    "        self.regularization=regularization\n",
    "\n",
    "        self.weight_input_hidden=np.random.randn(self.input_size,self.hidden_size)*np.sqrt(2.0 / self.input_size)\n",
    "        self.bias_hidden=np.zeros((1,self.hidden_size))\n",
    "        self.weights_hidden_output=np.random.randn(self.hidden_size,self.output_size)*np.sqrt(2.0 / self.hidden_size)\n",
    "        self.bias_output=np.zeros((1,self.output_size))\n",
    "\n",
    "    def relu(self,x):\n",
    "        return np.maximum(0,x)\n",
    "\n",
    "    def relu_derivative(self,x):\n",
    "        return np.where(x > 0, 1, 0)\n",
    "\n",
    "    def softmax(self,x):\n",
    "        exp_values=np.exp(x-np.max(x,axis=1,keepdims=True))\n",
    "        return exp_values/np.sum(exp_values,axis=1,keepdims=True)\n",
    "\n",
    "    def forward(self,X):\n",
    "        self.hidden_input= np.dot(X,self.weight_input_hidden)+self.bias_hidden\n",
    "        self.hidden_output=self.relu(self.hidden_input)\n",
    "        self.final_input=np.dot(self.hidden_output,self.weights_hidden_output)+self.bias_output\n",
    "        self.final_output=self.softmax(self.final_input)\n",
    "        return self.final_output\n",
    "\n",
    "    def backward(self,X,y,output):\n",
    "        self.error=y-output\n",
    "        self.output_gradient=self.error\n",
    "\n",
    "        self.hidden_error=self.output_gradient.dot(self.weights_hidden_output.T)\n",
    "        self.hidden_gradient=self.hidden_error*self.relu_derivative(self.hidden_output)\n",
    "\n",
    "        self.weights_hidden_output+=(np.dot(self.hidden_output.T,self.output_gradient)-self.regularization*self.weights_hidden_output)*self.learning_rate\n",
    "        self.bias_output+=np.sum(self.output_gradient,axis=0,keepdims=True)*learning_rate\n",
    "        self.weight_input_hidden+=(np.dot(X.T,self.hidden_gradient)-self.regularization*self.weight_input_hidden)*learning_rate\n",
    "        self.bias_hidden+=np.sum(self.hidden_gradient,axis=0,keepdims=True)*learning_rate\n",
    "\n",
    "\n",
    "    def train(self,X,y,epochs,batch_size=64):\n",
    "        sample_size=X.shape[0]\n",
    "        for epoch in range (epochs):\n",
    "            shuffle_index=np.random.permutation(sample_size)\n",
    "            X_shuffled=X[shuffle_index]\n",
    "            y_shuffled=y[shuffle_index]\n",
    "\n",
    "            for i in range(0,sample_size,batch_size):\n",
    "                X_batch=X_shuffled[i:i+batch_size]\n",
    "                y_batch=y_shuffled[i:i+batch_size]\n",
    "\n",
    "            output=self.forward(X_batch)\n",
    "            self.backward(X_batch,y_batch,output)\n",
    "\n",
    "            if (epoch+1)%10==0:\n",
    "                train_output=self.forward(X)\n",
    "                train_loss=-np.mean(np.sum(y*np.log(train_output+1e-8),axis=-1))\n",
    "\n",
    "                val_output=self.forward(X_test)\n",
    "                val_loss=-np.mean(np.sum(y_test*np.log(val_output+1e-8),axis=-1))\n",
    "\n",
    "                print(f'Epoch {epoch+1}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "    def predict(self,X):\n",
    "          output=self.forward(X)\n",
    "          return np.argmax(output,axis=1)\n",
    "\n",
    "\n",
    "\n",
    "input_size=784\n",
    "hidden_size=256\n",
    "output_size=10\n",
    "epochs=50\n",
    "regularization=0.001\n",
    "learning_rate=0.01\n",
    "\n",
    "X_train,y_train,X_test,y_test=load_data()\n",
    "n=Neural_network(input_size,hidden_size,output_size,learning_rate,regularization)\n",
    "\n",
    "n.train(X_train,y_train,epochs)\n",
    "predictions=n.predict(X_test)\n",
    "accuracy=np.mean(predictions==np.argmax(y_test,axis=1))*100\n",
    "print(f' Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "precision = np.zeros(output_size)\n",
    "for cls in range(output_size):\n",
    "    y_true_cls = (y_test[:, cls] == 1)\n",
    "    y_pred_cls = (predictions == cls)\n",
    "    precision[cls] = precision_score(y_true_cls, y_pred_cls)\n",
    "\n",
    "for i, prec in enumerate(precision):\n",
    "    print(f'Precision for class {i}: {prec:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32dcb371-7616-4b80-8426-89a3817e2d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 0.7016\n",
      "Epoch 20/100, Loss: 0.7332\n",
      "Epoch 30/100, Loss: 0.7718\n",
      "Epoch 40/100, Loss: 0.8112\n",
      "Epoch 50/100, Loss: 0.8494\n",
      "Epoch 60/100, Loss: 0.8857\n",
      "Epoch 70/100, Loss: 0.9200\n",
      "Epoch 80/100, Loss: 0.9524\n",
      "Epoch 90/100, Loss: 0.9829\n",
      "Epoch 100/100, Loss: 1.0118\n",
      "Test Accuracy: 92.92%\n",
      "Precision for class 1: 0.9474\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (569,) (113,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 143\u001b[0m\n\u001b[1;32m    139\u001b[0m X_unlabeled \u001b[38;5;241m=\u001b[39m load_unlabeled_data(unlabeled_data_file)\n\u001b[1;32m    142\u001b[0m predictions \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mpredict(X_unlabeled)\n\u001b[0;32m--> 143\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(predictions \u001b[38;5;241m==\u001b[39m y_test) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    146\u001b[0m prec \u001b[38;5;241m=\u001b[39m precision_score(y_test, predictions)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (569,) (113,) "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def precision_score(y_true, y_pred):\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    \n",
    "    if tp + fp == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return tp / (tp + fp)\n",
    "\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    data = pd.read_csv('data.csv')\n",
    "    data.drop(['Unnamed: 32', 'id'], axis=1, inplace=True)  # Remove unnecessary columns\n",
    "    data.diagnosis = [1 if each == \"M\" else 0 for each in data.diagnosis]  # Convert categorical labels to numeric\n",
    "\n",
    "    X = data.drop(['diagnosis'], axis=1).values\n",
    "    y = data.diagnosis.values\n",
    "\n",
    " \n",
    "    X = (X - np.min(X, axis=0)) / (np.max(X, axis=0) - np.min(X, axis=0))\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "X, y = load_data()\n",
    "\n",
    "def load_unlabeled_data(data_file):\n",
    "    data = pd.read_csv(data_file)\n",
    "    data.drop(['Unnamed: 32', 'id'], axis=1, inplace=True)\n",
    "    X = data.drop(['diagnosis'], axis=1).values\n",
    "    X = (X - np.min(X, axis=0)) / (np.max(X, axis=0) - np.min(X, axis=0))\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "def train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "    np.random.seed(random_state)\n",
    "    num_test = int(test_size * len(X))\n",
    "    indices = np.random.permutation(len(X))\n",
    "    train_indices, test_indices = indices[num_test:], indices[:num_test]\n",
    "    return X[train_indices], X[test_indices], y[train_indices], y[test_indices]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        \n",
    "        self.weights_input_hidden = np.random.randn(self.input_size, self.hidden_size) * np.sqrt(2.0 / self.input_size)\n",
    "        self.bias_hidden = np.zeros((1, self.hidden_size))\n",
    "        self.weights_hidden_output = np.random.randn(self.hidden_size, self.output_size) * np.sqrt(2.0 / self.hidden_size)\n",
    "        self.bias_output = np.zeros((1, self.output_size))\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def relu_derivative(self, x):\n",
    "        return np.where(x > 0, 1, 0)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def forward(self, X):\n",
    "     \n",
    "        self.hidden_input = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
    "        self.hidden_output = self.relu(self.hidden_input)\n",
    "        self.final_input = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output\n",
    "        self.final_output = self.sigmoid(self.final_input)\n",
    "        return self.final_output\n",
    "\n",
    "    def backward(self, X, y, output):\n",
    "        error = y.reshape(-1, 1) - output\n",
    "        output_gradient = error * output * (1 - output)\n",
    "        \n",
    "        hidden_error = np.dot(output_gradient, self.weights_hidden_output.T)\n",
    "        hidden_gradient = hidden_error * self.relu_derivative(self.hidden_output)\n",
    "        \n",
    "        \n",
    "        self.weights_hidden_output += np.dot(self.hidden_output.T, output_gradient) * self.learning_rate\n",
    "        self.bias_output += np.sum(output_gradient, axis=0, keepdims=True) * self.learning_rate\n",
    "        self.weights_input_hidden += np.dot(X.T, hidden_gradient) * self.learning_rate\n",
    "        self.bias_hidden += np.sum(hidden_gradient, axis=0, keepdims=True) * self.learning_rate\n",
    "\n",
    "    def train(self, X, y, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            output = self.forward(X)\n",
    "            self.backward(X, y, output)\n",
    "\n",
    "            \n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                loss = self.calculate_loss(X, y)\n",
    "                print(f'Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}')\n",
    "\n",
    "    def calculate_loss(self, X, y):\n",
    "        \n",
    "        output = self.forward(X)\n",
    "        loss = -np.mean(y * np.log(output) + (1 - y) * np.log(1 - output))\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        output = self.forward(X)\n",
    "        predictions = (output > 0.5).astype(int)\n",
    "        return predictions.ravel()\n",
    "\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 256\n",
    "output_size = 1  \n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "nn = NeuralNetwork(input_size, hidden_size, output_size, learning_rate)\n",
    "\n",
    "\n",
    "nn.train(X_train, y_train, epochs)\n",
    "\n",
    "\n",
    "predictions = nn.predict(X_test)\n",
    "accuracy = np.mean(predictions == y_test) * 100\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "prec = precision_score(y_test, predictions)\n",
    "print(f'Precision for class 1: {prec:.4f}')\n",
    "\n",
    "unlabeled_data_file = 'data.csv'\n",
    "X_unlabeled = load_unlabeled_data(unlabeled_data_file)\n",
    "\n",
    "\n",
    "predictions = nn.predict(X_unlabeled)\n",
    "accuracy = np.mean(predictions == y_test) * 100\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "prec = precision_score(y_test, predictions)\n",
    "print(f'Precision for class 1: {prec:.4f}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3216dd6e-b8b6-45e1-bf82-a3049c0a102f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
